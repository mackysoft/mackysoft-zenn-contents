---
title: "生成AI時代のVibe駆動開発はなぜ詰むのか―実装インフレで残るのは品質保証"
emoji: "🧠"
type: "idea"
topics: ["ai", "llm", "test", "設計", "品質"]
published: true
published_at: 2026-01-06 12:05
---

**Vibe駆動開発はクソである。**

## Vibeで詰みかけた
国内でもほぼ前例のない高難度R&Dをやっていた。
調べても答えが落ちていない。数式と向き合いながら精度を詰めていくしかない類のやつだ。

自分としても専門外の分野だったので、最初はAIに頼ってみた。
それっぽいプロンプトを投げ、AIにコードを書かせて、理解した気になりながら、Vibe的なお祈り駆動開発を進める。

**結果？失敗である。**
**つまるところ、Vibeで詰みかけた。**

そこから **「Vibe」を全て捨てた。**
真正面から数式と論文へと向き合い、基礎勉強主体に回帰した。その瞬間からグラフの精度は階段状に伸び始め、最終的には業界最高水準の精度でR&Dをクリアするに至った。

このまま自慢を続けたいところだが、NDAに引っかかるのでやめておこう。
代わりに、そこからたどり着いた結論、つまり **「Vibeはクソ」** について語る。

今から語るのはAI賛美でもAI否定でもない。
R&Dのフルセットを一人で背負いきった結果と体感から見えてきたものを、論理で結んだ構造論だ。

この記事では **「なぜVibe駆動開発がクソなのか」** と **「AI時代に人間がやるべき仕事は何か」** を殴り書きしていく。

:::message
この記事は、昨年時点で社内向けに投下した論考を、今の視点で再考察・再構築したものです。
:::

## 「Vibe」とは何か
**この記事で殴りに行くのは、「AIを使うこと」ではない。**
今から殴るのは、AIを用いた開発で起こりがちな次の運用である。

- 生成物を理解していないのに採用する
- 検証や根拠が後回しで、物量を進捗の根拠にする
- 「動いた」を正しさの代替に用いる
- 失敗しても原因分析ができずに、再度ガチャを回す

僕はこれを「お祈り駆動開発」と呼ぶこともあるが、この記事では便宜上 **「Vibe」** と呼ぶ。

## 点と線
この記事での抽象論を分かりやすくするために、先に僕の直感モデルを提示する。

- AIに知識を聞くのは、点を探索してもらう行為
- AIに実装を任せるのは、点と点を線で結ばせる行為

AIのおかげで点を集めるのは簡単になった。高難度R&Dですら、ニッチな原典の探索が容易になった。
**問題は線だ。**

Vibeの破綻パターンが何かと言えば、**自分の中で結びつきが不安定な点群同士を、AIに大量の線で結ばせることである。**

小さな点の集合なら、人間が暗黙知で補って決め打ちの線をAIに引かせることができる。
しかし、巨大な点群に大量の線を引かせようとすれば、人間の言語では意図を正確に伝えきることはできない。当然、線はズレる。

問題は、ズレた線がそれっぽく動いてしまうことである。
**動くから採用される。動くから負債になる。**

AIの出力をレビューするのは、この線の結びつきを確認して正しさを裏取りする作業だ。

AIに任せられるのはあくまでも、点を見つけることと、代理で線を引かせることと、補助線を描かせること。
ただし、**本線の正しさを保証する主体は、今のところ人間に残る。**

その直感を構造として書くのが、ここからの本題である。

---

## AIはレバレッジ装置
AI時代のアウトプットは、以下のような基本モデルで近似できる。
これは厳密なモデルというより、現状を認識するための認知モデルである。

> **アウトプットの質 = ベース能力 * AIの性能**

ここで言う「ベース能力」とは、「ドメイン知識」「抽象化能力」「大局観」みたいなやつを雑に全部まとめたものだ。
点と線を持ち出してみると、これは「点と点の間に引かれた線の正しさを評価する能力」と言える。

このモデルが示すのは、**「AIは土台がある者にしか本気で味方しない」** という、シンプルで残酷な事実である。

- ベースが低いと、AIの性能が上がっても質に対してレバレッジが乗らない
- ベースが高いと、AIの進化が勝手にレバレッジとして乗り、さらに強くなる

つまり、**AIは格差を埋める道具というより、ベースの差を増幅しやすい道具**になる。

### 上昇し続ける底
重要なのは、AIの性能係数は個人の努力とは関係なく、外部要因で上がる性質であることだ。
メガテックが勝手にAIを開発して、こちらはその恩恵を受ける。
いわばマップ兵器のようなもので、**AIが相対有利を作り出してくれるわけではない。**（モデルの差異はあるにせよ）

AIの性能向上によって起きるのは単に全体の底上げだ。しかも、数カ月単位で上昇し続けるめんどくさいやつ。これがAI時代における最低ラインである。
このAIで誰でも出せるアウトプットの質を **「コモディティライン」** と呼ぶことにする。

そして、**コモディティラインから上抜けるための鍵になるのがベース能力である。**
AIの性能係数がマップ兵器であるならば、付加価値はベース依存で決まらざるを得ないからだ。

なにより、**ベースの能力だけは自分で上げるしかない。**

### 「付加価値」とは
付加価値が何かと言えば、コモディティラインという絶対的な底からの相対的な差分だ。

> **付加価値 = 人間が出すアウトプットの質 - コモディティライン（≒ 1 * AIの性能）**

コモディティラインから上抜けるには、当然ながら **「付加価値 > 0」** でなければならない。

この構造を前提にすると、「ベースを育てずにAIに任せて走る」というVibe的な使い方は、中長期的な付加価値を相対的に削り、**自身をAIの単なるラッパーに押し込めることになる**と分かる。

## 認知がボトルネックになる
先のモデルを僕の体感に合わせ、ベース能力を少し分解する。

> **有効ベース = min(ベース能力, 認知能力)**
> **アウトプットの質 = 有効ベース * AIの性能**

「ベース能力」はドメイン理解を含む、その線が正しいかを説明できる能力のことだ。
「認知能力」とは、一度に追える状態の複雑性や、設計全体を頭に載せておける容量を指す。これは「どれだけ大量の線を同時に保持して保証できるか」の容量と捉えられる。

このモデルの重要な変化は、ボトルネックの性質が加わったことである。
この認知ボトルネックこそが、**AI時代の本当のボトルネック**となる。

Vibeが破綻するのは、**認知能力が追い付かないまま線だけを大量に生成させ、正しさの保証ができなくなるから**である。

僕がR&DでVibeを捨てた瞬間に精度が階段状に伸びたのは、ここが本質だ。
基礎勉強で理解を進めると、線の正しさを判定できるようになった。すると、線の塊をカプセル化して点として扱える。結果として認知負荷が下がり、実質的に認知能力が向上した。

このブレークスルーが起きたのは、AIによる生成から主導権を取り戻し、理解によって認知ボトルネックが外れたからだった。

たしかにAIは大量に線を生成できるようになったが、一方で線の正しさを保証する行為は人間の認知能力に縛られている。線を読む側が詰まり、線は供給過多だ。

つまり、**実装インフレ**である。

## 実装はインフレした
認知能力がボトルネックになっている現状で、**実装はほぼ無限に増やせる時代**が来た。
もはや、「コードは9割AI」「100％をAIで書いている」という話は珍しくない。

僕自身もCLIエージェントを用い、コーディングの9割をAIに任せて実装の物量を出すことはある。実装の供給量は一気に増えているし、コードを比較して、使わないものは簡単に捨てられる。

これが **「実装インフレ」** だ。
実装器が充足され始めたことで、コードを書くこと自体も、「大量に書いた」という事実も、そしてコードそのものの価値も**暴落**した。

しかし、ここで重要なのは「手で書いたか、AIが書いたか」ではない。
「AIで生成したコード割合」や「どれだけ大量のコードを生成したか」といった指標もあまり意味はない。

本質は、**「コードをAIで出力した人が、どのような指示と取捨選択によってその出力を採用・破棄したか」** というところにある。

実装器がほぼ完全に充足されたこの瞬間から、コードを書いてPRを投げれば良い時代は終了し、エンジニアの「作業者」としての側面は死んだ。そして生成が安くなるほど、希少になるのは「評価・検証し、正しさを保証する能力」である。

ここから数年のエンジニアの勝負所は、**実装ではなく保証** になる。
おそらく、これがエンジニアの最後の仕事なのではないかと見ている。

## 「保証」の時代
ここまでの話を整理するために、開発を3つの大まかなレイヤーに整理しておく。

- **実装**：仕様通りに動くものを作る
- **検証**：与えられた前提の中で、条件を満たしているかの証拠を作る
- **保証**：前提が現実に沿っているか、その検証で十分と言えるかまで含めて背負う行為

AIはすでに、実装レイヤーの大部分と、検証レイヤーのかなりの部分まで入り込んでいる。
**一方で、「この前提でこの検証なら十分です」と最後に言い切る保証レイヤーは、まだ人間が握っている。**

ここで言う「保証」についてもう少し詰めると、単に「テストが通る」ではない。

論拠を説明でき、
有効な証拠が揃っており、
第三者を納得させることができる。

**この状態を「保証」と呼ぶ。**
これがまさに、線による結びつきの正しさを保証する行為だ。

では何故、保証が人間に残るという発想に行き着いたか？
僕がやったようなR&Dで「AIで完全代替するには？」について真面目に考えると、どうしてもここにぶつかるからである。

### コンテキスト不完備である限り、AIは正しくない
AIの生成物は、**原理的に「正しさ」が保証されない。**
極端に言うと、仮に100点満点のコードを生成できるAIがあるだけでは、そのAIは「正しく」ならない。

なぜなら、プロジェクトの現実は**コンテキストの不完備**だからだ。

人類は今のところ、AIに対して意図を100％正確に伝える手段を発明していないし、そもそも自分自身も要件を完全に把握していない。ボトルネックの一つは間違いなく人間の認知である。

この制約を解決しない以上はAIの性能がどれだけ上がっても、**「前提の外側まで含めて正しくやってくれる存在」になり得ない。**
昨今のAIサービスでよく使われる定型句に「回答は必ずしも正しいとは限りません」というものがあるが、あれはハルシネーション云々の免責というよりも、構造的制約の暴露に近い。

だからこそ、どれだけ実装が上手いAIが登場したとしても、根本的な構造をひっくり返すような代物にはならない。
端的に言えば「マイクロマネジメントをしなくてもまともなコードを書いてくれる」程度のものに留まる。構造としては、依然として保証レイヤーに及ばない。

そして、この状況で「正しさ」を保証するには、必ず検証を挟まなければならない。

### 検証は保証にならない
ここまで読むと、「AIに検証を任せればそれでOKでは？」とも思うかもしれない。
実際、AIにレビューさせることもできるし、テストを書かせることもできる。
AIに検証をさせること自体は良い。

だが、**検証器がどれだけ強くなったとしても、それだけでは保証にならない。**
「検証」は「保証」の下層レイヤーだ。仮に完璧な検証器が存在するとしても構造上、保証者にはなれない。

人間がその検証器の正しさを保証しなければ、**それは空証明に留まる。**
では、なぜ空証明になるのかを詰めていこう。

**１．コンテキストが不完備**
前述の前提として、現実は常にコンテキスト不完備だ。

前提情報を片っ端からリポジトリに詰め込み、AIにコンテキストを渡して実装と検証をさせる。
その出力がそれっぽく見えたとして、現実的な前提を全て飲んだ上での出力だと言い切れるのか？

そこが怪しいままでは**保証にはならない。**
前提がズレていれば、検証自体がどれだけ完璧でも現実に対して誤る。

**２．経路が不明瞭**
「何故その結果に至ったか」という経路の問題もある。

なぜその結果を信じて良いのかが説明できない。
その経路が妥当かも分からない。
その結果が現実の前提条件や制約を満たすかも不明。

そんな状態ではプロジェクトを進められない。

ここは自身の経験で説明しよう。
僕はR&Dにおいて、最終的に理想的な出力精度を出せたし、何故その結果が出ているのか、なぜその経路がアルゴリズムとして正しいと言えるのかも、自分で説明できる状態に持って行っている。

もし、ここをAIに丸投げして「AIが勝手に実装して、テストを設計して、理想っぽい精度が出た」みたいな世界観で進めた場合、それらの説明が不能な状態になる。
僕の直感としては、その状態でプロジェクトを進めるのは無理だと感じた。

**「グラフが綺麗で精度も出てるっぽいからOK」は危険すぎる。**

たしかに、AIは証拠を集める検証エージェントにはなれる。
しかし、**検証器もその証拠も、誰かが保証しなければならない。**

そして、この保証の時代に必要なスキルが何かといえば、**「証拠の圧縮技術」** なのではないかと考えている。

### 証拠の圧縮
保証レイヤーを人間が握る以上、次のボトルネックは「検証をどれだけ早く回せるか」になる。
これからの時代の生産性は、**生成速度ではなく検証速度**で決まる。

AIの時代において、人間一人に求められるアウトプットの質は肥大化する。すると認知負荷が大きくなり過ぎて、保証が困難になる。

そこで必要になるのが、**「証拠の圧縮」** である。
検証から証拠を多数切り出し、意思決定に使える形で再現可能に小さく畳み直す。そのためのパイプラインを作る技術だ。
これは点と線の集合をカプセル化して点として扱うことで、人間が同時に扱う線の数を減らし、ボトルネックである認知能力を補う行為と言える。

求められるアウトプットが底上げされ続ける時代だからこそ、高認知負荷に耐えるための圧縮技術が必要になのである。

AIはある程度、この圧縮を代行してくれる。
テストコードを書かせたり、ログを要約させたり、異常を検知させる。

ただし、その圧縮によって得られる点群を証拠として採用するかを決め、結ばれた線の正しさを保証する判断主体は、現状だと**人間に残らざるを得ない。**

### 保証は上流へ逃げる
実装インフレによって、テストを書くこと自体は自動化できるようになった。エージェントによって、レビューも回せるようになった。
さらには、時代を経るたびに証拠は何重にも圧縮され、低層レイヤーのテストコードや細かい検証結果などはわざわざ読みに行く機会も減っていくだろう。

しかし、それは保証が必要なくなるという意味ではない。
保証するべき対象が、**「テストそのもの」から「前提や経路」へと移る**だけである。

長期的に見れば、**保証は上流レイヤーに移っていく。**
ここでは分かりやすくエンジニアリングの話をしているが、当然ながら保証はプロジェクトの企画やビジネスのレイヤーにまで及ぶ。
保証とは、プロジェクト全体を捉えた判断主体になることでもある。

そして、保証が上流に移るほど、**保証すべき対象を握れないVibeはなおさらリスクを孕む。**

## Vibeはなぜクソか

ここまでの話をまとめる。
Vibeの正体は、**「速度を前借りし、負債を未来に押し付けて後払いする技術」** だ。

Vibeは短期の速度は出せるが、**ベースと保証を放置**することになる。
そして、Vibeで負った負債は後払いしないといけないが、後払いが出来なくなると**中長期で詰む**ことになる。

**Vibeがクソなのは、この「後払い」がクソだからである。**

### Vibeは短期的には成立する
「AIがあれば、もうエンジニアいらなくないですか？」といったような煽りフレーズは時々観測される。
これはエンジニアを「作業者」の観点で見れば、ある程度正しい。
短期的にビジネスを回したり、問題のスケールとリスクが小さい領域ならVibeでも成立する局面はある。速度を前借りできるからだ。

**負債を踏み倒せる短期局面なら、Vibeはある程度合理的になる。**
実装インフレの恩恵を受ける最新技術に触るのは良い。凄いことやってる感も出る。

問題は、**それを開発の基本姿勢にしてしまうこと**にある。

### 保証の負債
Vibeは、**生成物の前提も経路も握らないし、握れない。**
だから、品質を保ちながらガチのプロダクトを作ろうとした瞬間に破綻し、「保証者」が必要になる。

前述のとおり、今の時代では検証は自動化され、証拠は圧縮される。
すると保証者は本来、より上流の前提や経路を相手にしなければならないが、Vibeはここを後払いにする。
「今動いている」や「検証は正しいっぽい」という事実を、そのまま正しさの代替にしてしまう。

短期的には速いが、その速さは **「保証の後払い」** で成り立っている。
**後払いが致命的な規模に達した瞬間、Vibeは止まる。**

### ベースの負債
実装器が充足されて以来、「AIで誰でもアプリを開発できる」と持て囃されることがある。
市場にないアイデアをすぐに形にしたり、誰でも手元で便利なツールを作れるという点で見れば、確かに価値がある。

ただし「誰でも」は、AIの性能依存になる。
ビジネス的な付加価値があるならまだしも、技術的に見れば**使用者の付加価値はほぼゼロになる。**

この世界で付加価値を作るには、ベース能力を上げてレバレッジをかけなければならない。
しかし、Vibeは「理解せずに採用する」という運用になりやすい。保証をする能力は育たず、点と線の結びつきが自分の中に残らない。

**Vibeに依存し続けるとベースが育たない。**
結果、AIはほとんどレバレッジを掛けてくれないため、中長期的な付加価値においてアドバンテージを失い、単なる**AIのラッパー**に留まることになる。

それは、**AI時代のエンジニアとしては詰み**である。

### なぜVibeにハマるのか
今はもう、AIの進化によってコモディティラインが上がり続ける時代に突入している。人間は、AIで出せる以上の付加価値を出さなければならない。

「AIで仕事の密度が上がって大変になった」という話はこれだ。
**AIで仕事は楽にならない。**

すると認知負荷が上がり続け、生成物の理解も保証もしないままで生成に逃げたくなる。特に経験が浅いほど、その誘惑が強くなる。僕が専門外分野のR&DでVibeを試したのはまさしくそれだ。
また、ジュニアがよく分からないコードのままPRを投げて上司を困らせる、みたいな話を小耳に挟むのも構造として自然だろう。

**Vibeは麻酔のようなものである。**

Vibeは、「今苦しい認知負荷」を消してくれる。
だが、その代償として **「ベース」と「保証」を放置** したままで、負債を未来に押し付ける。

**Vibeは罠だ。**

## AI時代の戦い方
ここまでの話を踏まえ、AI時代の戦い方をまとめる。

言っておくと、クソおもんない結論である。
なぜなら、僕がVibeを捨ててR&Dを突破したときの結論が、結局 **「基礎勉最強」** だったからだ。

### １．AIとの責任境界を引く
AIは判断主体にはなれない。少なくとも現状はそうだ。
僕がAIに任せて良いと考えているのは、基本的に「実装」と「検証」の側である。

- 点を探索させる（原典探索、要約）
- 線を仮引きさせる（試作）
- 線引きを代行させる（実装）
- 点と線の塊を圧縮させる（検証）

逆に、**人間が握るべきなのは「保証」だけである。**
ここを人間が握らなかったらVibeだ。

- 前提が現実に沿っていることを保証する
- 検証が十分であることを保証する
- 経路が妥当であると保証する

AIをうまく使うとは、AIに仕事を渡すことではない。
「どこから先を自分の責任にするか」を決めることである。

### ２．「保証プロトコル」を作る
保証レイヤーを握ると言っても、AIでインフレする時代に全てを頭で抱えるのは無理である。
だからこそ必要になるのが、前に書いた **「証拠の圧縮」** と、それを基にした **「保証プロトコル」** を作ることだ。

この「保証プロトコル」は、難しい話ではない。
人間が扱えるレベルの点として、大量の証拠を畳みなおすパイプラインを作ることで証拠を圧縮し、**「これでOK」と言える最低限の型**を決めればいい。

例えば、テストカバレッジとかCIパイプラインの成功あたりが保証プロトコルになる。
R&Dなら、ベンチマークの体系的なログ出力を用意し、その中でも重要な指標を決めておくことがそれに相当した。

AIには、保証プロトコルに必要な検証を手伝わせればいい。
**ただし、「正しく線が結ばれ、見るべき点として圧縮されているか」を判断し、保証プロトコルが十分だと言い切るところだけは、人間がやらなければならない。**

ここをAIに丸投げし、「AIが作ったテストを通ってるからOK」をやりだしたら、それはVibeだ。

### ３．ベースを上げる
ここで **「基礎勉最強」理論** になる。
    
**ベースが弱いと、そもそも保証プロトコルの設計ができない。**
AIにテストを書かせたとしても、そのテストによる検証が十分か判断できない。
アルゴリズムの経路が不明瞭なままだと、どこで破綻するのか説明できない。

保証レイヤーを握るためのベースとは、自分の頭の中で線を結び **「なぜその線が正しいか」を言い切れる能力**である。
ここでは特に面白みのあることは言えない。地味なことを日常的に積み上げるだけだ。

- 抽象化能力など、思考の基礎体力を鍛える
- 論文や公式ドキュメントやリポジトリのような原典を読む

学習には好きなだけAIを使えばいい。AIは便利だ。
僕も3歳児に戻って、片っ端から質問を投げたりする。
ただし、AIが出した要約や結論を「理解したつもり」で止めるとベースが育たない。

自分の頭の中で線が結ばれていないなら、保証に突入した瞬間に詰まることになる。
**保証を握るためのベースは、自分の頭で線を結ぶことで初めて増加する。**

ここまでに言ったことは楽ではないと思う。
しかし、コモディティラインが上がり続け、認知負荷が上がり続け、保証はどんどん上流に流れていく。
AI時代はそういう時代だ。

**だからこそ、これからのエンジニアは血反吐を吐きながら認知負荷に耐えてベースを強化しなければならない。**

## 普通の開発がR&D化する
ここまで書いてきた話の前提は、言ってしまえば**エンジニアリングの極北**に近いサンプルだ。
答えが落ちてないし、正解の形も揺れているし、点と線の集合が凄まじくて簡単に線が結べない。
一般論にするには極端すぎる。

ただ、これは特殊な例というよりも、AIが進化した先に人間に残る仕事の形が露呈した事例だと見ている。
AIがコードを書いたところで、要約で理解した気になったところで、突破できない問題があった。AIが握れる実装と検証だけではどうしようもなかった。
AIは保証を食えなかった。

その結果、Vibeの先にある「保証」が、**AI時代に人間がやるべき仕事の本質**として如実に炙り出された。

逆に、保証レイヤーを握らなくてもいい仕事は、AIにとって一番食いやすいレイヤーになる。AIは実装と検証を食える。
そうである以上、AIが実装や検証を食い尽くしてインフレしていく。
すると、あらゆるドメインでの **「普通の開発」自体が相対的にR&D寄り**にならざるを得ない。

それこそ、前例がほとんどないR&Dで、数式と論文にひたすら向き合い続けて、ひたすら高精度を求める…。
なんてことを全員やれという話ではないが、**僕がVibeを捨てた先にやったような種類の保証仕事がほとんどになっていくし、僕がR&Dで感じた種類の負荷がかかるようになってくるはずだ。**

つまり僕の経験から語ったことは、ここ数年で来る未来の分かりやすい縮図を表す。
**そんなAI時代の生存戦略が何かと言えば、これからの勝負どころである保証レイヤーに上がる覚悟だ。**

そして、もし保証そのものがAIに移る未来があるならば、それはプロジェクト最上流の判断主体が人間からAIに置き換わった時だろう。
AIがそこまで到達するのは、プロジェクトにおける人間以上の認知感覚とコンテキスト能力を備え、かつ人間と同等の実作業もこなせるようになった時だと考えている。
それができれば、コンテキスト不完備の前提を自力で補完し、世界モデルを構築できるからだ。

その時こそ本当に、保証レイヤーはAIに移り、僕は無職になっているはずだ。
ただ、そこに到達するまでは人間が正しさを保証するしかない。

## 結論
別にAI駆動開発を否定するわけではない。
僕はChatGPTと壁打ちしながら設計を詰めるのが好きだし、Claude Codeで物量を出すこともある。

ただ、ゾルトラークが一般攻撃魔法になったように、もはやAIは一般開発手法にすぎない。
だから大量のコードを生成することや、AIを使うこと自体を自慢してもあまり意味はないし、かと言って拒絶するのも違う。
**問題は「何を保証し、どこに責任を持つか」である。**

「人間に残る仕事は責任を取ることにある」という古い言説があるが、僕が述べた「保証」はそれの具体形と言える。
**保証とは責任であり、責任を持つ者は判断主体だ。**

しかし、Vibeは「保証レイヤー」の責任から逃げる習慣であり、AI時代の生存戦略とは真逆の方向に走る。
**だからこそ、Vibeはクソである。**

## おわりに

ここまで読んで少しでも刺さるものがあれば、ぜひシェアしたり、引用やコメントで意見とか反論を投げてもらえると嬉しいです。
これは僕一人の極端な経験から見えた「保証」の話なので、別の場所からの視点も気になるし、「こういう現実があるぞ」という話も歓迎します。

Vibe駆動開発に心当たりがありそうな同僚や知り合いに雑に投げて、議論の燃料にしてもらえたら本望です。